{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# architecture-27-3333\n",
    "\n",
    "## What's new:\n",
    "\n",
    "1-\n"
   ],
   "id": "fb927f0482914677"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Reshape, TimeDistributed, Lambda, LayerNormalization, Bidirectional, RepeatVector\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import talib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils.class_weight import compute_class_weight\n"
   ],
   "id": "4abc13163ee2d424",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1- Load and Scaling Features\n",
    "# Load and preprocess\n",
    "df = pd.read_csv('datasets-27-3333/XAGUSD-H1-rates.csv', sep='\\t')\n",
    "\n",
    "# Rename columns for easier access\n",
    "df.rename(columns={\n",
    "    '<DATE>': 'DATE',\n",
    "    '<TIME>': 'TIME',\n",
    "    '<OPEN>': 'OPEN',\n",
    "    '<HIGH>': 'HIGH',\n",
    "    '<LOW>': 'LOW',\n",
    "    '<CLOSE>': 'CLOSE',\n",
    "    '<TICKVOL>': 'TICKVOL',\n",
    "    '<VOL>': 'VOL',\n",
    "    '<SPREAD>': 'SPREAD'\n",
    "}, inplace=True)\n",
    "\n",
    "# Optional: Combine DATE and TIME into a single datetime column\n",
    "df['DATETIME'] = pd.to_datetime(df['DATE'] + ' ' + df['TIME'], errors='coerce')\n",
    "\n",
    "# Drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Sort data chronologically by DATETIME\n",
    "df.sort_values(by='DATETIME', inplace=True)\n",
    "\n",
    "# Reset index to ensure clean row order\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Select features to scale\n",
    "feature_cols = ['OPEN', 'HIGH', 'LOW', 'CLOSE', 'TICKVOL']\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "df[feature_cols] = scaler.fit_transform(df[feature_cols])"
   ],
   "id": "4c9a5a36c8be002e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 2- Label trend reversals\n",
    "def label_reversal_points(prices, window=8, threshold=0.002):\n",
    "    prices = np.asarray(prices)\n",
    "    labels = [0] * len(prices)\n",
    "    prev_trend = 0  # 1 = up, -1 = down, 0 = unknown\n",
    "\n",
    "    for i in range(len(prices) - window):\n",
    "        past = prices[i:i + window // 2]\n",
    "        future = prices[i + window // 2:i + window]\n",
    "\n",
    "        past_mean = np.mean(past)\n",
    "        future_mean = np.mean(future)\n",
    "        change = (future_mean - past_mean) / past_mean\n",
    "\n",
    "        if change > threshold:\n",
    "            curr_trend = 1  # Uptrend\n",
    "        elif change < -threshold:\n",
    "            curr_trend = -1  # Downtrend\n",
    "        else:\n",
    "            curr_trend = 0  # No significant trend\n",
    "\n",
    "        # Detect a reversal (trend direction changed)\n",
    "        if prev_trend == -1 and curr_trend == 1:\n",
    "            labels[i + window // 2] = 1  # Buy signal at start of uptrend\n",
    "        elif prev_trend == 1 and curr_trend == -1:\n",
    "            labels[i + window // 2] = 2  # Sell signal at start of downtrend\n",
    "\n",
    "        # Update previous trend only if there is a new clear trend\n",
    "        if curr_trend != 0:\n",
    "            prev_trend = curr_trend\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "df['Label'] = label_reversal_points(df['CLOSE'].values)"
   ],
   "id": "ce5f9c1ecf96cced",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 3- Create sequences\n",
    "SEQ_LEN = 60  # past candles for input\n",
    "FORECAST_HORIZON = 10  # predict next 10 candles\n",
    "NUM_CLASSES = 3  # 0 = no signal, 1 = buy, 2 = sell\n",
    "X, y = [], []\n",
    "for i in range(len(df) - SEQ_LEN - FORECAST_HORIZON + 1):\n",
    "    seq_x = df[feature_cols].iloc[i: i + SEQ_LEN].values\n",
    "    seq_y = df['Label'].iloc[i + SEQ_LEN: i + SEQ_LEN + FORECAST_HORIZON].values\n",
    "    X.append(seq_x)\n",
    "    y.append(seq_y)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ],
   "id": "7aaf04c111873e14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 4- One-hot encode labels for each timestep\n",
    "y_onehot = np.array([to_categorical(seq, num_classes=NUM_CLASSES) for seq in y])"
   ],
   "id": "f5c675eddb4bc802",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 5- Train-test split\n",
    "split = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y_onehot[:split], y_onehot[split:]\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)"
   ],
   "id": "9b787dab0031e409",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 6- Handle Class Imbalance\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Flatten labels to compute weights\n",
    "y_flat = np.argmax(y_train, axis=-1).flatten()\n",
    "class_weights_values = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.arange(NUM_CLASSES),\n",
    "    y=y_flat\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights_values))\n",
    "print(\"Class weights:\", class_weights)"
   ],
   "id": "ba0012e61d11b0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 7- Build LSTM Classification Model\n",
    "\n",
    "n_features = len(feature_cols)\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(SEQ_LEN, n_features)),\n",
    "    LSTM(128, return_sequences=False),\n",
    "    Dropout(0.3),\n",
    "    RepeatVector(FORECAST_HORIZON),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    TimeDistributed(Dense(NUM_CLASSES, activation='softmax'))\n",
    "])"
   ],
   "id": "fac9fc640f7a4d75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Convert your class_weights dict to a tensor\n",
    "weights = np.array([class_weights[i] for i in range(NUM_CLASSES)], dtype=np.float32)\n",
    "\n",
    "# ---- weighted loss (make broadcasting explicit & reduce over time) ----\n",
    "# Ensure weights array is float32\n",
    "weights = np.array([class_weights[i] for i in range(NUM_CLASSES)], dtype=np.float32)\n",
    "\n",
    "\n",
    "def weighted_categorical_crossentropy(weights_vec):\n",
    "    weights_tensor = K.constant(weights_vec)\n",
    "\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        # y_true: (batch, T, C) one-hot; y_pred: (batch, T, C)\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1.0 - K.epsilon())\n",
    "        w = K.reshape(weights_tensor, (1, 1, -1))  # shape (1,1,C) to broadcast over batch & time\n",
    "        per_timestep = -K.sum(y_true * K.log(y_pred) * w, axis=-1)  # (batch, T)\n",
    "        return K.mean(per_timestep, axis=-1)  # (batch,)\n",
    "\n",
    "    return loss_fn\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=weighted_categorical_crossentropy(weights),\n",
    "    metrics=['accuracy', 'mae']\n",
    ")\n"
   ],
   "id": "6474407f3f5a9c11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T16:27:43.837996Z",
     "start_time": "2025-08-15T16:23:57.821004Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 8- Fit model with EarlyStopping\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "rc = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=[es, rc],\n",
    "    verbose=1\n",
    ")\n",
    "# shuffle=False,  # Important: keep time order! ?????"
   ],
   "id": "f189dd95c6660684",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1755275040.120309   18591 cuda_dnn.cc:529] Loaded cuDNN version 91001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m10s\u001B[0m 9ms/step - accuracy: 0.3098 - loss: 1.0980 - mae: 0.4439 - val_accuracy: 0.8191 - val_loss: 1.0580 - val_mae: 0.4380 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 8ms/step - accuracy: 0.3055 - loss: 1.0997 - mae: 0.4443 - val_accuracy: 0.0552 - val_loss: 1.0594 - val_mae: 0.4427 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 8ms/step - accuracy: 0.3252 - loss: 1.1007 - mae: 0.4444 - val_accuracy: 0.8912 - val_loss: 1.0580 - val_mae: 0.4333 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001B[1m683/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.3976 - loss: 1.0965 - mae: 0.4436\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.3974 - loss: 1.0965 - mae: 0.4436 - val_accuracy: 0.8715 - val_loss: 1.0581 - val_mae: 0.4383 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 9ms/step - accuracy: 0.3826 - loss: 1.1003 - mae: 0.4445 - val_accuracy: 0.8860 - val_loss: 1.0581 - val_mae: 0.4386 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 9ms/step - accuracy: 0.4340 - loss: 1.0962 - mae: 0.4443 - val_accuracy: 0.8876 - val_loss: 1.0579 - val_mae: 0.4391 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001B[1m683/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.4058 - loss: 1.0964 - mae: 0.4442\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 9ms/step - accuracy: 0.4058 - loss: 1.0965 - mae: 0.4442 - val_accuracy: 0.8912 - val_loss: 1.0579 - val_mae: 0.4362 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 10ms/step - accuracy: 0.4414 - loss: 1.1017 - mae: 0.4443 - val_accuracy: 0.8912 - val_loss: 1.0579 - val_mae: 0.4358 - learning_rate: 2.5000e-04\n",
      "Epoch 9/50\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 9ms/step - accuracy: 0.4825 - loss: 1.0992 - mae: 0.4440 - val_accuracy: 0.8912 - val_loss: 1.0579 - val_mae: 0.4371 - learning_rate: 2.5000e-04\n",
      "Epoch 10/50\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 8ms/step - accuracy: 0.5030 - loss: 1.0960 - mae: 0.4437 - val_accuracy: 0.8912 - val_loss: 1.0579 - val_mae: 0.4380 - learning_rate: 2.5000e-04\n",
      "Epoch 11/50\n",
      "\u001B[1m683/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.4950 - loss: 1.0961 - mae: 0.4439\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 9ms/step - accuracy: 0.4949 - loss: 1.0961 - mae: 0.4439 - val_accuracy: 0.8912 - val_loss: 1.0579 - val_mae: 0.4372 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 9ms/step - accuracy: 0.5137 - loss: 1.0957 - mae: 0.4438 - val_accuracy: 0.8912 - val_loss: 1.0579 - val_mae: 0.4370 - learning_rate: 1.2500e-04\n",
      "Epoch 13/50\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 8ms/step - accuracy: 0.4919 - loss: 1.0952 - mae: 0.4439 - val_accuracy: 0.8912 - val_loss: 1.0578 - val_mae: 0.4374 - learning_rate: 1.2500e-04\n",
      "Epoch 14/50\n",
      "\u001B[1m687/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.4935 - loss: 1.0933 - mae: 0.4442\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.4935 - loss: 1.0934 - mae: 0.4442 - val_accuracy: 0.8903 - val_loss: 1.0579 - val_mae: 0.4377 - learning_rate: 1.2500e-04\n",
      "Epoch 15/50\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.4575 - loss: 1.0996 - mae: 0.4447 - val_accuracy: 0.8912 - val_loss: 1.0578 - val_mae: 0.4372 - learning_rate: 6.2500e-05\n",
      "Epoch 16/50\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.5038 - loss: 1.0944 - mae: 0.4439 - val_accuracy: 0.8912 - val_loss: 1.0578 - val_mae: 0.4372 - learning_rate: 6.2500e-05\n",
      "Epoch 17/50\n",
      "\u001B[1m684/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.4969 - loss: 1.0968 - mae: 0.4441\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.4969 - loss: 1.0968 - mae: 0.4441 - val_accuracy: 0.8912 - val_loss: 1.0578 - val_mae: 0.4369 - learning_rate: 6.2500e-05\n",
      "Epoch 18/50\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.4980 - loss: 1.1031 - mae: 0.4441 - val_accuracy: 0.8912 - val_loss: 1.0578 - val_mae: 0.4367 - learning_rate: 3.1250e-05\n",
      "Epoch 19/50\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 10ms/step - accuracy: 0.5221 - loss: 1.0974 - mae: 0.4437 - val_accuracy: 0.8912 - val_loss: 1.0578 - val_mae: 0.4371 - learning_rate: 3.1250e-05\n",
      "Epoch 20/50\n",
      "\u001B[1m687/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.5099 - loss: 1.0992 - mae: 0.4439\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.5099 - loss: 1.0992 - mae: 0.4439 - val_accuracy: 0.8912 - val_loss: 1.0578 - val_mae: 0.4371 - learning_rate: 3.1250e-05\n",
      "Epoch 21/50\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.5052 - loss: 1.0993 - mae: 0.4440 - val_accuracy: 0.8912 - val_loss: 1.0578 - val_mae: 0.4371 - learning_rate: 1.5625e-05\n",
      "Epoch 22/50\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 9ms/step - accuracy: 0.5080 - loss: 1.0970 - mae: 0.4439 - val_accuracy: 0.8911 - val_loss: 1.0578 - val_mae: 0.4373 - learning_rate: 1.5625e-05\n",
      "Epoch 23/50\n",
      "\u001B[1m685/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 7ms/step - accuracy: 0.4965 - loss: 1.0949 - mae: 0.4442\n",
      "Epoch 23: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.4965 - loss: 1.0949 - mae: 0.4442 - val_accuracy: 0.8912 - val_loss: 1.0578 - val_mae: 0.4372 - learning_rate: 1.5625e-05\n",
      "Epoch 24/50\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 8ms/step - accuracy: 0.5037 - loss: 1.0984 - mae: 0.4440 - val_accuracy: 0.8911 - val_loss: 1.0578 - val_mae: 0.4372 - learning_rate: 7.8125e-06\n",
      "Epoch 25/50\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 8ms/step - accuracy: 0.5042 - loss: 1.0970 - mae: 0.4440 - val_accuracy: 0.8912 - val_loss: 1.0578 - val_mae: 0.4372 - learning_rate: 7.8125e-06\n",
      "Epoch 26/50\n",
      "\u001B[1m687/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.5035 - loss: 1.0977 - mae: 0.4440\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 9ms/step - accuracy: 0.5035 - loss: 1.0977 - mae: 0.4440 - val_accuracy: 0.8912 - val_loss: 1.0578 - val_mae: 0.4372 - learning_rate: 7.8125e-06\n",
      "Epoch 27/50\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 9ms/step - accuracy: 0.5071 - loss: 1.1003 - mae: 0.4439 - val_accuracy: 0.8911 - val_loss: 1.0578 - val_mae: 0.4372 - learning_rate: 3.9063e-06\n",
      "Epoch 28/50\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 10ms/step - accuracy: 0.5054 - loss: 1.1001 - mae: 0.4440 - val_accuracy: 0.8911 - val_loss: 1.0578 - val_mae: 0.4372 - learning_rate: 3.9063e-06\n",
      "Epoch 29/50\n",
      "\u001B[1m684/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.5126 - loss: 1.0952 - mae: 0.4438\n",
      "Epoch 29: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 9ms/step - accuracy: 0.5126 - loss: 1.0952 - mae: 0.4438 - val_accuracy: 0.8911 - val_loss: 1.0578 - val_mae: 0.4372 - learning_rate: 3.9063e-06\n",
      "Epoch 30/50\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 9ms/step - accuracy: 0.5078 - loss: 1.0996 - mae: 0.4440 - val_accuracy: 0.8911 - val_loss: 1.0578 - val_mae: 0.4372 - learning_rate: 1.9531e-06\n",
      "Epoch 31/50\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 9ms/step - accuracy: 0.5094 - loss: 1.1007 - mae: 0.4439 - val_accuracy: 0.8911 - val_loss: 1.0578 - val_mae: 0.4372 - learning_rate: 1.9531e-06\n",
      "Epoch 32/50\n",
      "\u001B[1m687/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.5149 - loss: 1.0915 - mae: 0.4438\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 9ms/step - accuracy: 0.5149 - loss: 1.0915 - mae: 0.4438 - val_accuracy: 0.8911 - val_loss: 1.0578 - val_mae: 0.4372 - learning_rate: 1.9531e-06\n",
      "Epoch 33/50\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 9ms/step - accuracy: 0.5073 - loss: 1.0962 - mae: 0.4439 - val_accuracy: 0.8911 - val_loss: 1.0578 - val_mae: 0.4372 - learning_rate: 9.7656e-07\n",
      "Epoch 34/50\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 9ms/step - accuracy: 0.5063 - loss: 1.0935 - mae: 0.4439 - val_accuracy: 0.8911 - val_loss: 1.0578 - val_mae: 0.4372 - learning_rate: 9.7656e-07\n",
      "Epoch 35/50\n",
      "\u001B[1m685/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m━\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.5100 - loss: 1.0978 - mae: 0.4439\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m6s\u001B[0m 9ms/step - accuracy: 0.5099 - loss: 1.0978 - mae: 0.4439 - val_accuracy: 0.8911 - val_loss: 1.0578 - val_mae: 0.4372 - learning_rate: 9.7656e-07\n",
      "Epoch 36/50\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 9ms/step - accuracy: 0.5101 - loss: 1.0970 - mae: 0.4439 - val_accuracy: 0.8911 - val_loss: 1.0578 - val_mae: 0.4372 - learning_rate: 4.8828e-07\n",
      "Epoch 37/50\n",
      "\u001B[1m688/688\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m7s\u001B[0m 9ms/step - accuracy: 0.5067 - loss: 1.0963 - mae: 0.4439 - val_accuracy: 0.8911 - val_loss: 1.0578 - val_mae: 0.4372 - learning_rate: 4.8828e-07\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T16:27:55.348369Z",
     "start_time": "2025-08-15T16:27:53.739276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 11- Save Model\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 11-1 Create timestamp and paths\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "model_filename = f'model_{timestamp}.keras'\n",
    "model_path = os.path.join('saved_models', model_filename)\n",
    "\n",
    "# 11-2 Directory to hold logs and extras\n",
    "log_dir = os.path.join('saved_models', f'model_{timestamp}_logs')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# 11-3 Save model\n",
    "model.save(model_path)\n",
    "\n",
    "# 11-4 Save training history\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_csv(os.path.join(log_dir, 'training_history.csv'), index=False)\n",
    "\n",
    "# 11-5 Save training loss plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(log_dir, 'training_loss.png'))\n",
    "plt.close()\n",
    "\n",
    "# 11-6 Save model summary and final performance\n",
    "with open(os.path.join(log_dir, 'model_log.txt'), 'w') as f:\n",
    "    # Model architecture\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "\n",
    "    # Final metrics\n",
    "    final_train_loss = history.history['loss'][-1]\n",
    "\n",
    "    # Use y_test directly (already one-hot encoded from Step 4)\n",
    "    final_test_loss, final_test_accuracy, final_test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "    f.write(f'\\nFinal Training Loss: {final_train_loss:.6f}\\n')\n",
    "    f.write(f'Final Test Loss: {final_test_loss:.6f}\\n')\n",
    "    f.write(f'Final Test Accuracy: {final_test_accuracy:.6f}\\n')\n",
    "    f.write(f'Final Test MAE: {final_test_mae:.6f}\\n')\n",
    "\n",
    "print(f\"✅ Model and logs saved in: {log_dir}\")"
   ],
   "id": "c60adc7617c16b75",
   "outputs": [
    {
     "data": {
      "text/plain": [],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model and logs saved in: saved_models/model_20250815_195753_logs\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
