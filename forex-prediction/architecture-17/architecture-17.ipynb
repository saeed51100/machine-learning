{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# architecture-17 ( Basic Classification ) 10 label strategy it is not usefully\n",
    "\n",
    "## What's new:\n",
    "\n",
    "1- Add\n"
   ],
   "id": "67a9ecb3258e8606"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T07:48:02.657068Z",
     "start_time": "2025-07-30T07:47:55.429875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# Constants\n",
    "SEQUENCE_LENGTH = 60\n",
    "FORECAST_HORIZON = 10"
   ],
   "id": "e76513e71e49aa15",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-30 11:17:57.941740: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T07:48:08.027604Z",
     "start_time": "2025-07-30T07:48:07.911924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('datasets-17/XAGUSD-H1-rates.csv', sep='\\t').dropna()"
   ],
   "id": "4c9a5a36c8be002e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T07:48:09.329536Z",
     "start_time": "2025-07-30T07:48:09.299095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Scaling Features\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df[['<OPEN>', '<HIGH>', '<LOW>', '<CLOSE>', '<TICKVOL>']])"
   ],
   "id": "4e4c807682b6449b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T07:48:13.984541Z",
     "start_time": "2025-07-30T07:48:11.351878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Label trend reversals (example: a simplistic method)\n",
    "def label_trend_reversals(prices, window=5):\n",
    "    labels = []\n",
    "    for i in range(len(prices) - window):\n",
    "        past = prices[i:i+window//2]\n",
    "        future = prices[i+window//2:i+window]\n",
    "        if np.mean(future) > np.mean(past):\n",
    "            labels.append(1)  # potential buy\n",
    "        elif np.mean(future) < np.mean(past):\n",
    "            labels.append(2)  # potential sell\n",
    "        else:\n",
    "            labels.append(0)\n",
    "    labels += [0] * window  # pad\n",
    "    return labels\n",
    "\n",
    "df['Label'] = label_trend_reversals(df['<CLOSE>'].values)\n"
   ],
   "id": "ce5f9c1ecf96cced",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T07:48:19.673040Z",
     "start_time": "2025-07-30T07:48:17.066574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare Sequences\n",
    "X, y = [], []\n",
    "for i in range(SEQUENCE_LENGTH, len(scaled_data) - FORECAST_HORIZON):\n",
    "    X.append(scaled_data[i-SEQUENCE_LENGTH:i])\n",
    "    y.append(df['Label'].iloc[i:i+FORECAST_HORIZON].values)\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")  # Debug info"
   ],
   "id": "6dfd6176c12faccf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (55013, 60, 5), y shape: (55013, 10)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T07:48:50.786265Z",
     "start_time": "2025-07-30T07:48:50.779447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# === Split dataset ===\n",
    "X_train = X[:-1]\n",
    "y_train = y[:-1]\n",
    "X_test = X[-1:]\n",
    "y_test = np.array([to_categorical(y[-1], num_classes=3)])  # One-hot encode test label"
   ],
   "id": "9b787dab0031e409",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T07:49:42.114837Z",
     "start_time": "2025-07-30T07:49:42.108350Z"
    }
   },
   "cell_type": "code",
   "source": "X_train.shape",
   "id": "60cba69a1368de4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55012, 60, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Last 60 candles for prediction\n",
    "X_input = X[-1:]\n",
    "y_true_future = y[-1]  # for evaluation if desired\n"
   ],
   "id": "655fe1327365fc6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# One-hot encode each timestep's class (3 classes → depth = 3)\n",
    "y_onehot = np.array([to_categorical(row, num_classes=3) for row in y_train])\n",
    "# Now shape = (num_samples, 10, 3)\n"
   ],
   "id": "ba0012e61d11b0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Build LSTM Classification Model\n",
    "model = Sequential([\n",
    "    Input(shape=(SEQUENCE_LENGTH, X.shape[2])),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(FORECAST_HORIZON * 3, activation='softmax'),\n",
    "    tf.keras.layers.Reshape((FORECAST_HORIZON, 3))\n",
    "])\n"
   ],
   "id": "cf91bf473436a97e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
   "id": "7b500e9a255ca6e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fit model\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_onehot,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")"
   ],
   "id": "f189dd95c6660684",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# === Load the last 60 candles from a CSV file ===\n",
    "input_df = pd.read_csv(\n",
    "    'datasets-17/new-data-for-test/rows-60-from-20240503/rows-60-from-20240503.csv',\n",
    "    sep='\\t'\n",
    ").dropna()\n",
    "\n",
    "# Combine <DATE> and <TIME> into a datetime column\n",
    "input_df['DATETIME'] = pd.to_datetime(input_df['<DATE>'] + ' ' + input_df['<TIME>'])\n",
    "\n",
    "# === Prepare features and scale ===\n",
    "input_features = input_df[['<OPEN>', '<HIGH>', '<LOW>', '<CLOSE>', '<TICKVOL>']]\n",
    "input_scaled = scaler.transform(input_features)  # Use the same scaler from training\n",
    "\n",
    "# Reshape for model: (1, 60, num_features)\n",
    "input_sequence = np.expand_dims(input_scaled, axis=0)\n",
    "\n",
    "# === Predict class probabilities ===\n",
    "pred_probs = model.predict(input_sequence)  # e.g. shape: (1, 10 * 3)\n",
    "forecast_horizon = 10\n",
    "pred_classes = np.argmax(pred_probs.reshape(forecast_horizon, 3), axis=1)\n",
    "print(\"Predicted Classes:\", pred_classes)  # 0=no signal, 1=buy, 2=sell\n",
    "\n",
    "# === Generate future timestamps ===\n",
    "last_timestamp = input_df['DATETIME'].iloc[-1]\n",
    "forecast_datetimes = pd.date_range(start=last_timestamp + pd.Timedelta(hours=1),\n",
    "                                   periods=forecast_horizon, freq='h')\n",
    "\n",
    "# === Create predicted_df for plotting ===\n",
    "predicted_df = pd.DataFrame({\n",
    "    'DATETIME': forecast_datetimes,\n",
    "    'forecast_class': pred_classes\n",
    "})\n",
    "\n",
    "# Convert class → label\n",
    "def class_to_label(c):\n",
    "    return 'buy' if c == 1 else 'sell' if c == 2 else None\n",
    "\n",
    "predicted_df['label'] = predicted_df['forecast_class'].apply(class_to_label)\n"
   ],
   "id": "b27582fcf9337d79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# plot section",
   "id": "e31209f9cef74d45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(1, '../utils')\n",
    "import forex_plot_utils\n",
    "import os\n",
    "\n",
    "# PARAMETERS\n",
    "csv1_path = 'datasets-17/new-data-for-test/rows-60-from-20240503/latest-4-for-history.csv'\n",
    "csv3_path = 'datasets-17/new-data-for-test/rows-60-from-20240503/after.csv'\n",
    "plot_title = 'Write a suitable title.'\n",
    "output_plot_path = None  # e.g., 'output.png'\n",
    "\n",
    "# LOAD DATA FROM CSVS\n",
    "historical_df = forex_plot_utils.load_csv_with_datetime(csv1_path) if os.path.exists(csv1_path) else None\n",
    "actual_future_df = forex_plot_utils.load_csv_with_datetime(csv3_path) if os.path.exists(csv3_path) else None\n"
   ],
   "id": "cf739a571793a98b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# === Generate forecast timestamps ===\n",
    "# Start 1 hour after the last actual candle\n",
    "last_timestamp = input_df['DATETIME'].iloc[-1]\n",
    "forecast_datetimes = pd.date_range(start=last_timestamp + pd.Timedelta(hours=1), periods=forecast_horizon, freq='h')\n",
    "\n",
    "# === Create predicted_df with forecasted trend reversals ===\n",
    "predicted_df = pd.DataFrame({\n",
    "    'DATETIME': forecast_datetimes,\n",
    "    'forecast_class': pred_classes\n",
    "})\n",
    "\n",
    "# Optional: Add labels for plotting\n",
    "def class_to_label(c):\n",
    "    if c == 1:\n",
    "        return 'buy'\n",
    "    elif c == 2:\n",
    "        return 'sell'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "predicted_df['label'] = predicted_df['forecast_class'].apply(class_to_label)\n"
   ],
   "id": "41c58b92ac93caf0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# PLOT\n",
    "forex_plot_utils.plot_all_series(\n",
    "    historical_df=historical_df,\n",
    "    predicted_df=predicted_df,\n",
    "    actual_future_df=actual_future_df,\n",
    "    title=plot_title,\n",
    "    output_path=output_plot_path\n",
    ")"
   ],
   "id": "49ac94a3b618c89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Create timestamp and paths ===\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "model_filename = f'model_{timestamp}.keras'\n",
    "model_path = os.path.join('saved_models', model_filename)\n",
    "\n",
    "# Directory to hold logs and extras\n",
    "log_dir = os.path.join('saved_models', f'model_{timestamp}_logs')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# === Save model ===\n",
    "model.save(model_path)\n",
    "\n",
    "# === Save training history ===\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_csv(os.path.join(log_dir, 'training_history.csv'), index=False)\n",
    "\n",
    "# === Save training loss plot ===\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(log_dir, 'training_loss.png'))\n",
    "plt.close()\n",
    "\n",
    "# === Save model summary and final performance ===\n",
    "with open(os.path.join(log_dir, 'model_log.txt'), 'w') as f:\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "    final_train_loss = history.history['loss'][-1]\n",
    "    final_test_loss, final_test_mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "    f.write(f'\\nFinal Training Loss: {final_train_loss:.6f}\\n')\n",
    "    f.write(f'Final Test Loss: {final_test_loss:.6f}\\n')\n",
    "    f.write(f'Final Test MAE : {final_test_mae:.6f}\\n')\n"
   ],
   "id": "c60adc7617c16b75",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
