{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# classification-02\n",
    "\n",
    "## What's new:\n",
    "\n",
    "1-\n",
    "\n",
    "## next step:\n",
    "\n",
    "1- Improve labeling ( 3333 from 28-1111 )\n"
   ],
   "id": "67a9ecb3258e8606"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Reshape, TimeDistributed, Lambda\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import talib\n"
   ],
   "id": "e76513e71e49aa15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1- Load and Scaling Features\n",
    "\n",
    "df = pd.read_csv('XAGUSD-197001010000--H1-rates.csv', sep='\\t')\n",
    "# Rename columns for easier access\n",
    "df.rename(columns={\n",
    "    '<DATE>': 'DATE',\n",
    "    '<TIME>': 'TIME',\n",
    "    '<OPEN>': 'OPEN',\n",
    "    '<HIGH>': 'HIGH',\n",
    "    '<LOW>': 'LOW',\n",
    "    '<CLOSE>': 'CLOSE',\n",
    "    '<TICKVOL>': 'TICKVOL',\n",
    "    '<VOL>': 'VOL',\n",
    "    '<SPREAD>': 'SPREAD'\n",
    "}, inplace=True)\n",
    "\n",
    "# ensure strings and strip any weird whitespace\n",
    "df['DATE'] = df['DATE'].astype(str).str.strip()\n",
    "df['TIME'] = df['TIME'].astype(str).str.strip()\n",
    "\n",
    "df['DATETIME'] = pd.to_datetime(df['DATE'] + ' ' + df['TIME'], dayfirst=False, errors='coerce')\n",
    "if df['DATETIME'].isna().any():\n",
    "    raise ValueError(\"Some DATETIME values could not be parsed. Check date/time formats.\")\n",
    "\n",
    "# set DATETIME as index for reindexing\n",
    "df = df.set_index('DATETIME').sort_index()\n",
    "\n",
    "# --------------------------\n",
    "# Create continuous hourly index & fill weekend gaps\n",
    "# --------------------------\n",
    "full_index = pd.date_range(start=df.index.min(), end=df.index.max(), freq='h')\n",
    "\n",
    "# Reindex to full hourly range so weekends/missing hours appear as NaN rows\n",
    "df = df.reindex(full_index)\n",
    "\n",
    "# Fill strategy:\n",
    "# - Prices: forward-fill last known price across weekend gap (common approach for modeling continuity).\n",
    "# - TICKVOL / VOL: set missing to 0 (no ticks during weekend).\n",
    "# - SPREAD: forward-fill last known.\n",
    "# Alternative: you could leave NaNs and drop sequences that cross weekends (safer but reduces data).\n",
    "df[['OPEN', 'HIGH', 'LOW', 'CLOSE']] = df[['OPEN', 'HIGH', 'LOW', 'CLOSE']].ffill()\n",
    "df['SPREAD'] = df['SPREAD'].ffill()\n",
    "df['TICKVOL'] = df['TICKVOL'].fillna(0)\n",
    "df['VOL'] = df['VOL'].fillna(0)\n",
    "\n",
    "# Reset index to make DATETIME a regular column again\n",
    "df = df.reset_index().rename(columns={'index': 'DATETIME'})"
   ],
   "id": "7754644750a0b8db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.shape",
   "id": "e7923b89f6b69488",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example: choose the start and end rows\n",
    "start_row = 32200\n",
    "end_row = 33000\n",
    "\n",
    "# Select the range and make a copy to avoid SettingWithCopyWarning\n",
    "subset = df.iloc[start_row:end_row + 1].copy()\n",
    "\n",
    "# Ensure DATETIME is datetime type\n",
    "subset['DATETIME'] = pd.to_datetime(subset['DATETIME'])\n",
    "\n",
    "# Plot CLOSE price over time\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(subset['DATETIME'], subset['CLOSE'], linewidth=1.0, color='blue')\n",
    "\n",
    "# Labels and formatting\n",
    "plt.title(f\"Price Chart from Row {start_row} to {end_row}\", fontsize=14)\n",
    "plt.xlabel(\"Datetime\", fontsize=12)\n",
    "plt.ylabel(\"Close Price\", fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "9fe95d0a7b4893b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Specify how many rows to remove for model\n",
    "nn = 33000   # Delete the first nn rows that do not follow the one-hour timeframe.\n",
    "mm = 500   # Remove mm last row that the model should not see.\n",
    "\n",
    "# Delete first nn and last mm rows\n",
    "df_model = df.iloc[nn:len(df)-mm].reset_index(drop=True)"
   ],
   "id": "477c8b58b48e9dfb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 2- Label trend reversals (example: a simplistic method)\n",
    "def label_reversal_points(prices, window=8, threshold=0.002):\n",
    "    prices = np.asarray(prices)\n",
    "    labels = [0] * len(prices)\n",
    "    prev_trend = 0  # 1 = up, -1 = down, 0 = unknown\n",
    "\n",
    "    for i in range(len(prices) - window):\n",
    "        past = prices[i:i + window // 2]\n",
    "        future = prices[i + window // 2:i + window]\n",
    "\n",
    "        past_mean = np.mean(past)\n",
    "        future_mean = np.mean(future)\n",
    "        change = (future_mean - past_mean) / past_mean\n",
    "\n",
    "        if change > threshold:\n",
    "            curr_trend = 1  # Uptrend\n",
    "        elif change < -threshold:\n",
    "            curr_trend = -1  # Downtrend\n",
    "        else:\n",
    "            curr_trend = 0  # No significant trend\n",
    "\n",
    "        # Detect a reversal (trend direction changed)\n",
    "        if prev_trend == -1 and curr_trend == 1:\n",
    "            labels[i + window // 2] = 1  # Buy signal at start of uptrend\n",
    "        elif prev_trend == 1 and curr_trend == -1:\n",
    "            labels[i + window // 2] = 2  # Sell signal at start of downtrend\n",
    "\n",
    "        # Update previous trend only if there is a new clear trend\n",
    "        if curr_trend != 0:\n",
    "            prev_trend = curr_trend\n",
    "\n",
    "    return labels\n",
    "\n",
    "df_model['Label'] = label_reversal_points(df_model['CLOSE'].values)"
   ],
   "id": "ae894c87b56a1558",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(df_model['Label'].value_counts().sort_index())  # 0, 1, 2",
   "id": "918427444f51dceb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_labeled_candles(df, n=190):\n",
    "    \"\"\"\n",
    "    Plots the last n candles with BUY/SELL labels based on the 'Label' column.\n",
    "    Assumes df already has a 'DATETIME' column.\n",
    "    \"\"\"\n",
    "    # Drop NaN rows (e.g., weekend gaps)\n",
    "    df_plot = df.dropna(subset=['CLOSE']).tail(n).copy()\n",
    "\n",
    "    # Ensure DATETIME is a datetime column (optional safeguard)\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df_plot['DATETIME']):\n",
    "        df_plot['DATETIME'] = pd.to_datetime(df_plot['DATETIME'])\n",
    "\n",
    "    # === Plot Close Price ===\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(df_plot['DATETIME'], df_plot['CLOSE'], label='Close Price', color='black', linewidth=1.5)\n",
    "\n",
    "    # === Plot BUY (1) and SELL (2) signals ===\n",
    "    for _, row in df_plot.iterrows():\n",
    "        if row['Label'] == 1:  # BUY\n",
    "            plt.axvline(x=row['DATETIME'], color='green', linestyle='--', linewidth=1)\n",
    "            plt.text(row['DATETIME'], row['CLOSE'], 'BUY', color='green', ha='center', va='bottom', fontsize=9)\n",
    "        elif row['Label'] == 2:  # SELL\n",
    "            plt.axvline(x=row['DATETIME'], color='red', linestyle='--', linewidth=1)\n",
    "            plt.text(row['DATETIME'], row['CLOSE'], 'SELL', color='red', ha='center', va='top', fontsize=9)\n",
    "\n",
    "    # === Aesthetics ===\n",
    "    plt.title(f'Last {n} Candles with Trend Reversal Labels')\n",
    "    plt.xlabel('Datetime')\n",
    "    plt.ylabel('Close Price')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, linestyle='--', alpha=0.4)\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n"
   ],
   "id": "d27ed135157f8837",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_labeled_candles(df_model)",
   "id": "9d9e40e665da9f3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Select features to scale\n",
    "features = ['OPEN', 'HIGH', 'LOW', 'CLOSE', 'TICKVOL']\n",
    "\n",
    "# Apply MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(df_model[features])"
   ],
   "id": "f8eee5c58c507b27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 3- Prepare Sequences\n",
    "\n",
    "given_time = \"2024.05.03 01:00:00\"   # starting datetime\n",
    "WINDOW_SIZE = 60\n",
    "FORECAST_HORIZON = 10\n",
    "X, y = [], []\n",
    "\n",
    "for i in range(WINDOW_SIZE, len(scaled) - FORECAST_HORIZON):\n",
    "    X_seq = scaled[i - WINDOW_SIZE:i]  # (60, 5)\n",
    "    y_seq = df_model['Label'].iloc[i:i + FORECAST_HORIZON].values  # 10 labels (0/1/2)\n",
    "    X.append(X_seq)\n",
    "    y.append(y_seq)\n",
    "\n",
    "X = np.array(X)  # shape: (samples, 60, 5)\n",
    "y = np.array(y)  # shape: (samples, 10)"
   ],
   "id": "ab8d6d6b923f830b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 4- Split dataset\n",
    "# Reserve last sample as test input\n",
    "X_train, y_train = X[:-1], y[:-1]\n",
    "X_test, y_test = X[-1:], y[-1:]"
   ],
   "id": "9b787dab0031e409",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 5- One-hot encode each timestep's class (3 classes â†’ depth = 3)\n",
    "# Convert labels to one-hot for each timestep\n",
    "y_train_onehot = np.array([to_categorical(seq, num_classes=3) for seq in y_train])\n",
    "y_test_onehot = np.array([to_categorical(seq, num_classes=3) for seq in y_test])\n"
   ],
   "id": "ba0012e61d11b0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 6- Build LSTM Classification Model\n",
    "model = Sequential([\n",
    "    Input(shape=(WINDOW_SIZE, X.shape[2])),  # (60, 5)\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    TimeDistributed(Dense(64, activation='relu')),\n",
    "    TimeDistributed(Dense(3, activation='softmax')),\n",
    "    Lambda(lambda x: x[:, -FORECAST_HORIZON:, :])  # Keep only last 10 timesteps\n",
    "])\n"
   ],
   "id": "cf91bf473436a97e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 7- Compile model\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\n",
    "        tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "        tf.keras.metrics.TopKCategoricalAccuracy(k=2, name='top_2_accuracy')\n",
    "    ]\n",
    ")"
   ],
   "id": "7b500e9a255ca6e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 8- Fit model\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_onehot,\n",
    "    epochs=50,  # adjust based on convergence\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    shuffle=False,  # Important: keep time order!\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n"
   ],
   "id": "f189dd95c6660684",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "67892e8ce905fa80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# === Load and clean the last 60 rows from a separate CSV file for prediction ===\n",
    "# --- Find the starting index ---\n",
    "start_idx = df.index[df['DATETIME'] == pd.to_datetime(given_time)][0]\n",
    "\n",
    "# --- 1. Extract next n candles ---\n",
    "input_df = df.iloc[start_idx : start_idx + WINDOW_SIZE].copy()\n",
    "\n",
    "\n",
    "# Scale\n",
    "input_features = input_df[['OPEN', 'HIGH', 'LOW', 'CLOSE', 'TICKVOL']]\n",
    "input_scaled = scaler.transform(input_features)\n",
    "input_sequence = np.expand_dims(input_scaled, axis=0)  # (1, 60, 5)\n",
    "\n",
    "# Predict\n",
    "pred_probs = model.predict(input_sequence)  # shape: (1, 10, 3)\n",
    "pred_classes = np.argmax(pred_probs[0], axis=1)\n",
    "print(\"Predicted Classes:\", pred_classes)  # 0=no signal, 1=buy, 2=sell\n",
    "\n",
    "# Timestamps for forecast\n",
    "last_timestamp = input_df['DATETIME'].iloc[-1]\n",
    "datetime_index = pd.date_range(start=last_timestamp + pd.Timedelta(hours=1),\n",
    "                                   periods=FORECAST_HORIZON, freq='h')\n",
    "\n",
    "# Output DataFrame\n",
    "predicted_df = pd.DataFrame({\n",
    "    'DATETIME': datetime_index,\n",
    "    'forecast_class': pred_classes\n",
    "})\n",
    "predicted_df['label'] = predicted_df['forecast_class'].map({1: 'buy', 2: 'sell'}).fillna('')\n",
    "\n",
    "print(predicted_df)\n"
   ],
   "id": "b27582fcf9337d79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# plot section",
   "id": "e31209f9cef74d45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# --- 2. Extract last 4 candles from input_df ---\n",
    "historical_df = input_df.tail(4).copy()\n",
    "\n",
    "# --- 3. Extract next 10 candles immediately after input_df ---\n",
    "actual_future_df = df.iloc[start_idx + WINDOW_SIZE - 1 : start_idx + WINDOW_SIZE + FORECAST_HORIZON].copy()\n",
    "\n",
    "plot_title = 'Actual vs Predicted Forex Closing Prices'\n",
    "output_plot_path = None  # e.g., 'output.png'\n",
    "\n",
    "\n",
    "# 10-3 Generate forecast timestamps ===\n",
    "# Start 1 hour after the last actual candle\n",
    "last_timestamp = input_df['DATETIME'].iloc[-1]\n",
    "datetime_index = pd.date_range(start=last_timestamp + pd.Timedelta(hours=1), periods=FORECAST_HORIZON, freq='h')\n",
    "\n",
    "# 10-4 Create predicted_df with forecasted trend reversals\n",
    "predicted_df = pd.DataFrame({\n",
    "    'DATETIME': datetime_index,\n",
    "    'forecast_class': pred_classes\n",
    "})\n",
    "\n",
    "\n",
    "# 10-5 Optional: Add labels for plotting\n",
    "def class_to_label(c):\n",
    "    if c == 1:\n",
    "        return 'buy'\n",
    "    elif c == 2:\n",
    "        return 'sell'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "predicted_df['label'] = predicted_df['forecast_class'].apply(class_to_label)\n"
   ],
   "id": "cf739a571793a98b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 10-6 PLOT\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../utils')\n",
    "import forex_plot_utils_2\n",
    "\n",
    "# PLOT\n",
    "forex_plot_utils_2.plot_all_series(\n",
    "    historical_df=historical_df,\n",
    "    predicted_df=predicted_df,\n",
    "    actual_future_df=actual_future_df,\n",
    "    title=plot_title,\n",
    "    output_path=output_plot_path\n",
    ")\n",
    "\n"
   ],
   "id": "49ac94a3b618c89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 11- Save Model\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 11-1 Create timestamp and paths\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "model_filename = f'model_{timestamp}.keras'\n",
    "model_path = os.path.join('saved_models', model_filename)\n",
    "\n",
    "# 11-2 Directory to hold logs and extras\n",
    "log_dir = os.path.join('saved_models', f'model_{timestamp}_logs')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# 11-3 Save model\n",
    "model.save(model_path)\n",
    "\n",
    "# 11-4 Save training history\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_csv(os.path.join(log_dir, 'training_history.csv'), index=False)\n",
    "\n",
    "# 11-5 Save training loss plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(log_dir, 'training_loss.png'))\n",
    "plt.close()\n",
    "\n",
    "# 11-6 Save model summary and final performance\n",
    "y_test_onehot = to_categorical(y_test, num_classes=3)\n",
    "\n",
    "with open(os.path.join(log_dir, 'model_log.txt'), 'w') as f:\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "    final_train_loss = history.history['loss'][-1]\n",
    "    final_test_loss, final_test_accuracy, final_test_mae = model.evaluate(X_test, y_test_onehot, verbose=0)\n",
    "\n",
    "    f.write(f'\\nFinal Training Loss: {final_train_loss:.6f}\\n')\n",
    "    f.write(f'Final Test Loss: {final_test_loss:.6f}\\n')\n",
    "    f.write(f'Final Test Accuracy: {final_test_accuracy:.6f}\\n')"
   ],
   "id": "c60adc7617c16b75",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
