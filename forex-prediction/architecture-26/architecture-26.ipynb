{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# architecture-26 ( Basic Classification ) v-10\n",
    "\n",
    "## What's new:\n",
    "\n",
    "1- Without RSI\n",
    "\n",
    "2- add labels only start and end of trends.\n"
   ],
   "id": "fb927f0482914677"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Reshape, TimeDistributed, Lambda, LayerNormalization, Bidirectional\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import talib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n"
   ],
   "id": "4abc13163ee2d424",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1- Load and Scaling Features\n",
    "# Load and preprocess\n",
    "df = pd.read_csv('datasets-26/XAGUSD-H1-rates.csv', sep='\\t')\n",
    "\n",
    "# Rename columns for easier access\n",
    "df.rename(columns={\n",
    "    '<DATE>': 'DATE',\n",
    "    '<TIME>': 'TIME',\n",
    "    '<OPEN>': 'OPEN',\n",
    "    '<HIGH>': 'HIGH',\n",
    "    '<LOW>': 'LOW',\n",
    "    '<CLOSE>': 'CLOSE',\n",
    "    '<TICKVOL>': 'TICKVOL',\n",
    "    '<VOL>': 'VOL',\n",
    "    '<SPREAD>': 'SPREAD'\n",
    "}, inplace=True)\n",
    "\n",
    "# Optional: Combine DATE and TIME into a single datetime column\n",
    "df['DATETIME'] = pd.to_datetime(df['DATE'] + ' ' + df['TIME'], errors='coerce')\n",
    "\n",
    "# Drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Sort data chronologically by DATETIME\n",
    "df.sort_values(by='DATETIME', inplace=True)\n",
    "\n",
    "# Reset index to ensure clean row order\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Select features to scale\n",
    "features = ['OPEN', 'HIGH', 'LOW', 'CLOSE', 'TICKVOL']\n",
    "\n",
    "# Apply MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df[features])"
   ],
   "id": "4c9a5a36c8be002e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 2- Label trend reversals (example: a simplistic method)\n",
    "def label_reversal_points(prices, window=8, threshold=0.002):\n",
    "    prices = np.asarray(prices)\n",
    "    labels = [0] * len(prices)\n",
    "    prev_trend = 0  # 1 = up, -1 = down, 0 = unknown\n",
    "\n",
    "    for i in range(len(prices) - window):\n",
    "        past = prices[i:i + window // 2]\n",
    "        future = prices[i + window // 2:i + window]\n",
    "\n",
    "        past_mean = np.mean(past)\n",
    "        future_mean = np.mean(future)\n",
    "        change = (future_mean - past_mean) / past_mean\n",
    "\n",
    "        if change > threshold:\n",
    "            curr_trend = 1  # Uptrend\n",
    "        elif change < -threshold:\n",
    "            curr_trend = -1  # Downtrend\n",
    "        else:\n",
    "            curr_trend = 0  # No significant trend\n",
    "\n",
    "        # Detect a reversal (trend direction changed)\n",
    "        if prev_trend == -1 and curr_trend == 1:\n",
    "            labels[i + window // 2] = 1  # Buy signal at start of uptrend\n",
    "        elif prev_trend == 1 and curr_trend == -1:\n",
    "            labels[i + window // 2] = 2  # Sell signal at start of downtrend\n",
    "\n",
    "        # Update previous trend only if there is a new clear trend\n",
    "        if curr_trend != 0:\n",
    "            prev_trend = curr_trend\n",
    "\n",
    "    return labels\n",
    "\n",
    "df['Label'] = label_reversal_points(df['CLOSE'].values)"
   ],
   "id": "ce5f9c1ecf96cced",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_labeled_candles(df, n=150):\n",
    "    \"\"\"\n",
    "    Plots the last n candles with BUY/SELL labels based on the 'Label' column.\n",
    "    \"\"\"\n",
    "    # Use only the last n rows\n",
    "    df_plot = df.tail(n).copy()\n",
    "    df_plot['DATETIME'] = df_plot['DATE'] + ' ' + df_plot['TIME']\n",
    "\n",
    "    # Plot the closing price\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(df_plot['DATETIME'], df_plot['CLOSE'], label='Close Price', color='black', linewidth=1.5)\n",
    "\n",
    "    # Plot BUY (label=1) and SELL (label=2) signals\n",
    "    for idx, row in df_plot.iterrows():\n",
    "        if row['Label'] == 1:\n",
    "            plt.axvline(x=row['DATETIME'], color='green', linestyle='--', linewidth=1)\n",
    "            plt.text(row['DATETIME'], row['CLOSE'], 'BUY', color='green', ha='center', va='bottom', fontsize=9)\n",
    "        elif row['Label'] == 2:\n",
    "            plt.axvline(x=row['DATETIME'], color='red', linestyle='--', linewidth=1)\n",
    "            plt.text(row['DATETIME'], row['CLOSE'], 'SELL', color='red', ha='center', va='top', fontsize=9)\n",
    "\n",
    "    plt.title(f'Last {n} Candles with Trend Reversal Labels')\n",
    "    plt.xlabel('Datetime')\n",
    "    plt.ylabel('Close Price')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, linestyle='--', alpha=0.4)\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "id": "f9561a3916eeb381",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_labeled_candles(df)",
   "id": "479bf6b01d78980b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 3- Prepare Sequences\n",
    "# Constants\n",
    "INPUT_WINDOW = 60   # past 60 candles\n",
    "FORECAST_HORIZON = 10  # predict next 10 reversal points\n",
    "NUM_CLASSES = 3     # [0: no reversal, 1: buy, 2: sell]\n",
    "\n",
    "# Ensure data is scaled and labeled already\n",
    "features = df[['OPEN', 'HIGH', 'LOW', 'CLOSE', 'TICKVOL', 'VOL', 'SPREAD']].values\n",
    "labels = df['Label'].values\n",
    "\n",
    "# Create sequences and labels\n",
    "X, y = [], []\n",
    "\n",
    "for i in range(len(features) - INPUT_WINDOW - FORECAST_HORIZON + 1):\n",
    "    X.append(features[i:i+INPUT_WINDOW])\n",
    "    y.append(labels[i+INPUT_WINDOW:i+INPUT_WINDOW+FORECAST_HORIZON])\n",
    "\n",
    "X = np.array(X)  # Shape: (samples, 60, features)\n",
    "y = np.array(y)  # Shape: (samples, 10)\n",
    "\n",
    "# Convert labels to categorical (multi-class)\n",
    "y_cat = to_categorical(y, num_classes=NUM_CLASSES)  # Shape: (samples, 10, 3)\n",
    "\n",
    "# Split data\n",
    "\n"
   ],
   "id": "7aaf04c111873e14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 4- Split dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_cat, test_size=0.1, random_state=42)"
   ],
   "id": "9b787dab0031e409",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# 5- One-hot encode each timestep's class (3 classes â†’ depth = 3)\n",
   "id": "ba0012e61d11b0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 6- Build LSTM Classification Model\n",
    "input_shape = X_train.shape[1:]  # (60, num_features)\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "x = LayerNormalization()(inputs)\n",
    "x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = LSTM(64)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "\n",
    "# Output 10 time steps of classification\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(FORECAST_HORIZON * NUM_CLASSES)(x)  # Flattened output\n",
    "outputs = tf.keras.layers.Reshape((FORECAST_HORIZON, NUM_CLASSES))(x)\n",
    "outputs = tf.keras.layers.Softmax(axis=-1)(outputs)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "model.summary()\n",
    "\n"
   ],
   "id": "cf91bf473436a97e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 7- Compile the Model (Handle Class Imbalance)\n",
    "# Calculate class weights for labels 1 and 2\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Flatten the true class labels for class weight calculation\n",
    "flat_labels = np.argmax(y_train, axis=-1).flatten()\n",
    "class_weights_raw = compute_class_weight(class_weight='balanced', classes=np.arange(NUM_CLASSES), y=flat_labels)\n",
    "\n",
    "# Convert to dictionary\n",
    "class_weights = {i: w for i, w in enumerate(class_weights_raw)}\n",
    "print(\"Class Weights:\", class_weights)\n",
    "\n",
    "# Use custom loss with class weights\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    weights = K.constant(weights)\n",
    "\n",
    "    def loss(y_true, y_pred):\n",
    "        y_true = K.cast(y_true, tf.float32)\n",
    "        loss = y_true * K.log(y_pred + 1e-8) * weights\n",
    "        return -K.mean(K.sum(loss, axis=-1))\n",
    "\n",
    "    return loss\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss=weighted_categorical_crossentropy(class_weights),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n"
   ],
   "id": "7b500e9a255ca6e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 8- Fit model\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n",
    "rc = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, verbose=1)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=[es, rc],\n",
    "    shuffle=False,  # Important: keep time order!\n",
    "    verbose=1\n",
    ")\n",
    "# shuffle=False,  # Important: keep time order! ?????\n"
   ],
   "id": "f189dd95c6660684",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 9- Load the last 60 candles from a CSV file\n",
    "\n",
    "# Load and clean\n",
    "input_df = pd.read_csv('datasets-26/new-data-for-test/rows-60-from-20240503/rows-60-from-20240503.csv', sep='\\t')\n",
    "input_df.dropna(inplace=True)\n",
    "\n",
    "input_df.rename(columns={\n",
    "    '<DATE>': 'DATE',\n",
    "    '<TIME>': 'TIME',\n",
    "    '<OPEN>': 'OPEN',\n",
    "    '<HIGH>': 'HIGH',\n",
    "    '<LOW>': 'LOW',\n",
    "    '<CLOSE>': 'CLOSE',\n",
    "    '<TICKVOL>': 'TICKVOL',\n",
    "    '<VOL>': 'VOL',\n",
    "    '<SPREAD>': 'SPREAD'\n",
    "}, inplace=True)\n",
    "\n",
    "# Add datetime\n",
    "input_df['DATETIME'] = pd.to_datetime(input_df['DATE'] + ' ' + input_df['TIME'])\n",
    "\n",
    "# Scale\n",
    "input_features = input_df[['OPEN', 'HIGH', 'LOW', 'CLOSE', 'TICKVOL']]\n",
    "input_scaled = scaler.transform(input_features)\n",
    "input_sequence = np.expand_dims(input_scaled, axis=0)  # (1, 60, 5)\n",
    "\n",
    "# Predict\n",
    "pred_probs = model.predict(input_sequence)  # shape: (1, 10, 3)\n",
    "pred_classes = np.argmax(pred_probs[0], axis=1)\n",
    "print(\"Predicted Classes:\", pred_classes)  # 0=no signal, 1=buy, 2=sell\n",
    "\n",
    "# Timestamps for forecast\n",
    "last_timestamp = input_df['DATETIME'].iloc[-1]\n",
    "forecast_datetimes = pd.date_range(start=last_timestamp + pd.Timedelta(hours=1),\n",
    "                                   periods=FORECAST_HORIZON, freq='h')\n",
    "\n",
    "# Output DataFrame\n",
    "predicted_df = pd.DataFrame({\n",
    "    'DATETIME': forecast_datetimes,\n",
    "    'forecast_class': pred_classes\n",
    "})\n",
    "predicted_df['label'] = predicted_df['forecast_class'].map({1: 'buy', 2: 'sell'}).fillna('')\n",
    "\n",
    "print(predicted_df)\n"
   ],
   "id": "b27582fcf9337d79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# plot section",
   "id": "e31209f9cef74d45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 10- Plot section\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, '../utils')\n",
    "import forex_plot_utils\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 10-1 PARAMETERS\n",
    "csv1_path = 'datasets-26/new-data-for-test/rows-60-from-20240503/latest-4-for-history.csv'\n",
    "csv3_path = 'datasets-26/new-data-for-test/rows-60-from-20240503/after.csv'\n",
    "plot_title = 'Write a suitable title.'\n",
    "output_plot_path = None  # e.g., 'output.png'\n",
    "\n",
    "# 10-2 LOAD DATA FROM CSVS\n",
    "historical_df = forex_plot_utils.load_csv_with_datetime(csv1_path) if os.path.exists(csv1_path) else None\n",
    "actual_future_df = forex_plot_utils.load_csv_with_datetime(csv3_path) if os.path.exists(csv3_path) else None\n",
    "# 10-3 Generate forecast timestamps ===\n",
    "# Start 1 hour after the last actual candle\n",
    "last_timestamp = input_df['DATETIME'].iloc[-1]\n",
    "forecast_datetimes = pd.date_range(start=last_timestamp + pd.Timedelta(hours=1), periods=FORECAST_HORIZON, freq='h')\n",
    "\n",
    "# 10-4 Create predicted_df with forecasted trend reversals\n",
    "predicted_df = pd.DataFrame({\n",
    "    'DATETIME': forecast_datetimes,\n",
    "    'forecast_class': pred_classes\n",
    "})\n",
    "\n",
    "\n",
    "# 10-5 Optional: Add labels for plotting\n",
    "def class_to_label(c):\n",
    "    if c == 1:\n",
    "        return 'buy'\n",
    "    elif c == 2:\n",
    "        return 'sell'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "predicted_df['label'] = predicted_df['forecast_class'].apply(class_to_label)\n"
   ],
   "id": "cf739a571793a98b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 10-6 PLOT\n",
    "\n",
    "forex_plot_utils.plot_all_series(\n",
    "    historical_df=historical_df,\n",
    "    predicted_df=predicted_df,\n",
    "    actual_future_df=actual_future_df,\n",
    "    title=plot_title,\n",
    "    output_path=output_plot_path\n",
    ")"
   ],
   "id": "49ac94a3b618c89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 11- Save Model\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 11-1 Create timestamp and paths\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "model_filename = f'model_{timestamp}.keras'\n",
    "model_path = os.path.join('saved_models', model_filename)\n",
    "\n",
    "# 11-2 Directory to hold logs and extras\n",
    "log_dir = os.path.join('saved_models', f'model_{timestamp}_logs')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# 11-3 Save model\n",
    "model.save(model_path)\n",
    "\n",
    "# 11-4 Save training history\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_csv(os.path.join(log_dir, 'training_history.csv'), index=False)\n",
    "\n",
    "# 11-5 Save training loss plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(log_dir, 'training_loss.png'))\n",
    "plt.close()\n",
    "\n",
    "# 11-6 Save model summary and final performance\n",
    "y_test_onehot = to_categorical(y_test, num_classes=3)\n",
    "\n",
    "with open(os.path.join(log_dir, 'model_log.txt'), 'w') as f:\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "    final_train_loss = history.history['loss'][-1]\n",
    "    final_test_loss, final_test_accuracy, final_test_mae = model.evaluate(X_test, y_test_onehot, verbose=0)\n",
    "\n",
    "    f.write(f'\\nFinal Training Loss: {final_train_loss:.6f}\\n')\n",
    "    f.write(f'Final Test Loss: {final_test_loss:.6f}\\n')\n",
    "    f.write(f'Final Test Accuracy: {final_test_accuracy:.6f}\\n')"
   ],
   "id": "c60adc7617c16b75",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
