{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# architecture-27 ( Basic Classification ) v-11\n",
    "\n",
    "## What's new:\n",
    "\n",
    "1-\n"
   ],
   "id": "fb927f0482914677"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Input, Reshape, TimeDistributed, Lambda, LayerNormalization, Bidirectional\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import talib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n"
   ],
   "id": "4abc13163ee2d424",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1- Load and Scaling Features\n",
    "# Load and preprocess\n",
    "df = pd.read_csv('datasets-27/XAGUSD-H1-rates.csv', sep='\\t')\n",
    "\n",
    "# Rename columns for easier access\n",
    "df.rename(columns={\n",
    "    '<DATE>': 'DATE',\n",
    "    '<TIME>': 'TIME',\n",
    "    '<OPEN>': 'OPEN',\n",
    "    '<HIGH>': 'HIGH',\n",
    "    '<LOW>': 'LOW',\n",
    "    '<CLOSE>': 'CLOSE',\n",
    "    '<TICKVOL>': 'TICKVOL',\n",
    "    '<VOL>': 'VOL',\n",
    "    '<SPREAD>': 'SPREAD'\n",
    "}, inplace=True)\n",
    "\n",
    "# Optional: Combine DATE and TIME into a single datetime column\n",
    "df['DATETIME'] = pd.to_datetime(df['DATE'] + ' ' + df['TIME'], errors='coerce')\n",
    "\n",
    "# Drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Sort data chronologically by DATETIME\n",
    "df.sort_values(by='DATETIME', inplace=True)\n",
    "\n",
    "# Reset index to ensure clean row order\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Select features to scale\n",
    "feature_cols = ['OPEN', 'HIGH', 'LOW', 'CLOSE', 'TICKVOL']\n",
    "\n",
    "# 4. Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "df[feature_cols] = scaler.fit_transform(df[feature_cols])"
   ],
   "id": "4c9a5a36c8be002e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 2- Label trend reversals (example: a simplistic method)\n",
    "def label_reversal_points(prices, window=8, threshold=0.002):\n",
    "    prices = np.asarray(prices)\n",
    "    labels = [0] * len(prices)\n",
    "    prev_trend = 0  # 1 = up, -1 = down, 0 = unknown\n",
    "\n",
    "    for i in range(len(prices) - window):\n",
    "        past = prices[i:i + window // 2]\n",
    "        future = prices[i + window // 2:i + window]\n",
    "\n",
    "        past_mean = np.mean(past)\n",
    "        future_mean = np.mean(future)\n",
    "        change = (future_mean - past_mean) / past_mean\n",
    "\n",
    "        if change > threshold:\n",
    "            curr_trend = 1  # Uptrend\n",
    "        elif change < -threshold:\n",
    "            curr_trend = -1  # Downtrend\n",
    "        else:\n",
    "            curr_trend = 0  # No significant trend\n",
    "\n",
    "        # Detect a reversal (trend direction changed)\n",
    "        if prev_trend == -1 and curr_trend == 1:\n",
    "            labels[i + window // 2] = 1  # Buy signal at start of uptrend\n",
    "        elif prev_trend == 1 and curr_trend == -1:\n",
    "            labels[i + window // 2] = 2  # Sell signal at start of downtrend\n",
    "\n",
    "        # Update previous trend only if there is a new clear trend\n",
    "        if curr_trend != 0:\n",
    "            prev_trend = curr_trend\n",
    "\n",
    "    return labels\n",
    "\n",
    "df['Label'] = label_reversal_points(df['CLOSE'].values)"
   ],
   "id": "ce5f9c1ecf96cced",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_labeled_candles(df, n=150):\n",
    "    \"\"\"\n",
    "    Plots the last n candles with BUY/SELL labels based on the 'Label' column.\n",
    "    \"\"\"\n",
    "    # Use only the last n rows\n",
    "    df_plot = df.tail(n).copy()\n",
    "    df_plot['DATETIME'] = df_plot['DATE'] + ' ' + df_plot['TIME']\n",
    "\n",
    "    # Plot the closing price\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.plot(df_plot['DATETIME'], df_plot['CLOSE'], label='Close Price', color='black', linewidth=1.5)\n",
    "\n",
    "    # Plot BUY (label=1) and SELL (label=2) signals\n",
    "    for idx, row in df_plot.iterrows():\n",
    "        if row['Label'] == 1:\n",
    "            plt.axvline(x=row['DATETIME'], color='green', linestyle='--', linewidth=1)\n",
    "            plt.text(row['DATETIME'], row['CLOSE'], 'BUY', color='green', ha='center', va='bottom', fontsize=9)\n",
    "        elif row['Label'] == 2:\n",
    "            plt.axvline(x=row['DATETIME'], color='red', linestyle='--', linewidth=1)\n",
    "            plt.text(row['DATETIME'], row['CLOSE'], 'SELL', color='red', ha='center', va='top', fontsize=9)\n",
    "\n",
    "    plt.title(f'Last {n} Candles with Trend Reversal Labels')\n",
    "    plt.xlabel('Datetime')\n",
    "    plt.ylabel('Close Price')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.grid(True, linestyle='--', alpha=0.4)\n",
    "    plt.tight_layout()\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "id": "f9561a3916eeb381",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_labeled_candles(df)",
   "id": "479bf6b01d78980b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create sequences\n",
    "SEQ_LEN = 60      # past candles for input\n",
    "FORECAST_HORIZON = 10  # predict next 10 candles\n",
    "NUM_CLASSES = 3   # 0 = no signal, 1 = buy, 2 = sell\n",
    "X, y = [], []\n",
    "for i in range(len(df) - SEQ_LEN - FORECAST_HORIZON + 1):\n",
    "    seq_x = df[feature_cols].iloc[i : i + SEQ_LEN].values\n",
    "    seq_y = df['Label'].iloc[i + SEQ_LEN : i + SEQ_LEN + FORECAST_HORIZON].values\n",
    "    X.append(seq_x)\n",
    "    y.append(seq_y)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ],
   "id": "7aaf04c111873e14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# One-hot encode labels for each timestep\n",
    "y_onehot = np.array([to_categorical(seq, num_classes=NUM_CLASSES) for seq in y])"
   ],
   "id": "f5c675eddb4bc802",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Train-test split\n",
    "split = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y_onehot[:split], y_onehot[split:]\n",
    "\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"y_train:\", y_train.shape)"
   ],
   "id": "9b787dab0031e409",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 4- Handle Class Imbalance\n",
    "# ==============================\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Flatten labels to compute weights\n",
    "y_flat = np.argmax(y_train, axis=-1).flatten()\n",
    "class_weights_values = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.arange(NUM_CLASSES),\n",
    "    y=y_flat\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights_values))\n",
    "print(\"Class weights:\", class_weights)"
   ],
   "id": "ba0012e61d11b0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 5- Build LSTM Classification Model\n",
    "# ==============================\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, TimeDistributed\n",
    "\n",
    "from tensorflow.keras.layers import RepeatVector\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(128, return_sequences=False, input_shape=(SEQ_LEN, len(feature_cols))),\n",
    "    Dropout(0.3),\n",
    "    RepeatVector(FORECAST_HORIZON),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    TimeDistributed(Dense(NUM_CLASSES, activation='softmax'))\n",
    "])\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Convert your class_weights dict to a tensor\n",
    "weights = np.array([class_weights[i] for i in range(NUM_CLASSES)], dtype=np.float32)\n",
    "\n",
    "def weighted_categorical_crossentropy(weights):\n",
    "    weights_tensor = K.constant(weights)\n",
    "\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        # Avoid log(0)\n",
    "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "        # Calculate loss for each class and apply weights\n",
    "        loss = y_true * K.log(y_pred) * weights_tensor\n",
    "        loss = -K.sum(loss, axis=-1)  # sum over classes\n",
    "        return loss\n",
    "    return loss_fn\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=weighted_categorical_crossentropy(weights),\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ],
   "id": "6474407f3f5a9c11",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 9. Fit model with EarlyStopping\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=20,\n",
    "    batch_size=64\n",
    ")\n",
    "# shuffle=False,  # Important: keep time order! ?????\n"
   ],
   "id": "f189dd95c6660684",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 9- Load the last 60 candles from a CSV file\n",
    "\n",
    "# Load and clean\n",
    "input_df = pd.read_csv('datasets-27/new-data-for-test/rows-60-from-20240503/rows-60-from-20240503.csv', sep='\\t')\n",
    "input_df.dropna(inplace=True)\n",
    "\n",
    "input_df.rename(columns={\n",
    "    '<DATE>': 'DATE',\n",
    "    '<TIME>': 'TIME',\n",
    "    '<OPEN>': 'OPEN',\n",
    "    '<HIGH>': 'HIGH',\n",
    "    '<LOW>': 'LOW',\n",
    "    '<CLOSE>': 'CLOSE',\n",
    "    '<TICKVOL>': 'TICKVOL',\n",
    "    '<VOL>': 'VOL',\n",
    "    '<SPREAD>': 'SPREAD'\n",
    "}, inplace=True)\n",
    "\n",
    "# Add datetime\n",
    "input_df['DATETIME'] = pd.to_datetime(input_df['DATE'] + ' ' + input_df['TIME'])\n",
    "\n",
    "# Scale\n",
    "input_features = input_df[['OPEN', 'HIGH', 'LOW', 'CLOSE', 'TICKVOL']]\n",
    "input_scaled = scaler.transform(input_features)\n",
    "input_sequence = np.expand_dims(input_scaled, axis=0)  # (1, 60, 5)\n",
    "\n",
    "# Predict\n",
    "pred_probs = model.predict(input_sequence)  # shape: (1, 10, 3)\n",
    "pred_classes = np.argmax(pred_probs[0], axis=1)\n",
    "print(\"Predicted Classes:\", pred_classes)  # 0=no signal, 1=buy, 2=sell\n",
    "\n",
    "# Timestamps for forecast\n",
    "last_timestamp = input_df['DATETIME'].iloc[-1]\n",
    "forecast_datetimes = pd.date_range(start=last_timestamp + pd.Timedelta(hours=1),\n",
    "                                   periods=FORECAST_HORIZON, freq='h')\n",
    "\n",
    "# Output DataFrame\n",
    "predicted_df = pd.DataFrame({\n",
    "    'DATETIME': forecast_datetimes,\n",
    "    'forecast_class': pred_classes\n",
    "})\n",
    "predicted_df['label'] = predicted_df['forecast_class'].map({1: 'buy', 2: 'sell'}).fillna('')\n",
    "\n",
    "print(predicted_df)\n"
   ],
   "id": "b27582fcf9337d79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# plot section",
   "id": "e31209f9cef74d45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 10- Plot section\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, '../utils')\n",
    "import forex_plot_utils\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 10-1 PARAMETERS\n",
    "csv1_path = 'datasets-27/new-data-for-test/rows-60-from-20240503/latest-4-for-history.csv'\n",
    "csv3_path = 'datasets-27/new-data-for-test/rows-60-from-20240503/after.csv'\n",
    "plot_title = 'Write a suitable title.'\n",
    "output_plot_path = None  # e.g., 'output.png'\n",
    "\n",
    "# 10-2 LOAD DATA FROM CSVS\n",
    "historical_df = forex_plot_utils.load_csv_with_datetime(csv1_path) if os.path.exists(csv1_path) else None\n",
    "actual_future_df = forex_plot_utils.load_csv_with_datetime(csv3_path) if os.path.exists(csv3_path) else None\n",
    "# 10-3 Generate forecast timestamps ===\n",
    "# Start 1 hour after the last actual candle\n",
    "last_timestamp = input_df['DATETIME'].iloc[-1]\n",
    "forecast_datetimes = pd.date_range(start=last_timestamp + pd.Timedelta(hours=1), periods=FORECAST_HORIZON, freq='h')\n",
    "\n",
    "# 10-4 Create predicted_df with forecasted trend reversals\n",
    "predicted_df = pd.DataFrame({\n",
    "    'DATETIME': forecast_datetimes,\n",
    "    'forecast_class': pred_classes\n",
    "})\n",
    "\n",
    "\n",
    "# 10-5 Optional: Add labels for plotting\n",
    "def class_to_label(c):\n",
    "    if c == 1:\n",
    "        return 'buy'\n",
    "    elif c == 2:\n",
    "        return 'sell'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "predicted_df['label'] = predicted_df['forecast_class'].apply(class_to_label)\n"
   ],
   "id": "cf739a571793a98b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 10-6 PLOT\n",
    "\n",
    "forex_plot_utils.plot_all_series(\n",
    "    historical_df=historical_df,\n",
    "    predicted_df=predicted_df,\n",
    "    actual_future_df=actual_future_df,\n",
    "    title=plot_title,\n",
    "    output_path=output_plot_path\n",
    ")"
   ],
   "id": "49ac94a3b618c89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 11- Save Model\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 11-1 Create timestamp and paths\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "model_filename = f'model_{timestamp}.keras'\n",
    "model_path = os.path.join('saved_models', model_filename)\n",
    "\n",
    "# 11-2 Directory to hold logs and extras\n",
    "log_dir = os.path.join('saved_models', f'model_{timestamp}_logs')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# 11-3 Save model\n",
    "model.save(model_path)\n",
    "\n",
    "# 11-4 Save training history\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_csv(os.path.join(log_dir, 'training_history.csv'), index=False)\n",
    "\n",
    "# 11-5 Save training loss plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(log_dir, 'training_loss.png'))\n",
    "plt.close()\n",
    "\n",
    "# 11-6 Save model summary and final performance\n",
    "y_test_onehot = to_categorical(y_test, num_classes=3)\n",
    "\n",
    "with open(os.path.join(log_dir, 'model_log.txt'), 'w') as f:\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "    final_train_loss = history.history['loss'][-1]\n",
    "    final_test_loss, final_test_accuracy, final_test_mae = model.evaluate(X_test, y_test_onehot, verbose=0)\n",
    "\n",
    "    f.write(f'\\nFinal Training Loss: {final_train_loss:.6f}\\n')\n",
    "    f.write(f'Final Test Loss: {final_test_loss:.6f}\\n')\n",
    "    f.write(f'Final Test Accuracy: {final_test_accuracy:.6f}\\n')"
   ],
   "id": "c60adc7617c16b75",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
