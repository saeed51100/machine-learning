{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# architecture-18 ( Basic Classification ) v-2\n",
    "\n",
    "## What's new:\n",
    "\n",
    "1- Add\n"
   ],
   "id": "67a9ecb3258e8606"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout,Input, Reshape\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ],
   "id": "e76513e71e49aa15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1- Load and Scaling Features\n",
    "\n",
    "# Load and preprocess\n",
    "df = pd.read_csv('datasets-18/XAGUSD-H1-rates.csv', sep='\\t')\n",
    "\n",
    "# Rename columns for easier access\n",
    "df.rename(columns={\n",
    "    '<DATE>': 'DATE',\n",
    "    '<TIME>': 'TIME',\n",
    "    '<OPEN>': 'OPEN',\n",
    "    '<HIGH>': 'HIGH',\n",
    "    '<LOW>': 'LOW',\n",
    "    '<CLOSE>': 'CLOSE',\n",
    "    '<TICKVOL>': 'TICKVOL',\n",
    "    '<VOL>': 'VOL',\n",
    "    '<SPREAD>': 'SPREAD'\n",
    "}, inplace=True)\n",
    "\n",
    "# Optional: Combine DATE and TIME into a single datetime column\n",
    "df['DATETIME'] = pd.to_datetime(df['DATE'] + ' ' + df['TIME'])\n",
    "\n",
    "# Drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Select features to scale\n",
    "features = ['OPEN', 'HIGH', 'LOW', 'CLOSE', 'TICKVOL']\n",
    "\n",
    "# Apply MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(df[features])"
   ],
   "id": "4c9a5a36c8be002e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# 2- Label trend reversals (example: a simplistic method)\n",
    "\n",
    "def label_trend_reversals(prices, window=5, threshold=0.0005):\n",
    "    prices = np.asarray(prices)\n",
    "    labels = []\n",
    "\n",
    "    for i in range(len(prices) - window):\n",
    "        past = prices[i:i + window // 2]\n",
    "        future = prices[i + window // 2:i + window]\n",
    "\n",
    "        past_mean = np.mean(past)\n",
    "        future_mean = np.mean(future)\n",
    "\n",
    "        if future_mean > past_mean * (1 + threshold):\n",
    "            labels.append(1)  # potential buy\n",
    "        elif future_mean < past_mean * (1 - threshold):\n",
    "            labels.append(2)  # potential sell\n",
    "        else:\n",
    "            labels.append(0)  # no signal\n",
    "\n",
    "    # Padding the end with zeros\n",
    "    labels += [0] * window\n",
    "    return labels\n",
    "\n",
    "# Apply labeling on cleaned DataFrame\n",
    "df['Label'] = label_trend_reversals(df['CLOSE'].values, window=10, threshold=0.001)\n"
   ],
   "id": "ce5f9c1ecf96cced",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 3- Prepare Sequences\n",
    "\n",
    "SEQUENCE_LENGTH = 60\n",
    "FORECAST_HORIZON = 10\n",
    "X, y = [], []\n",
    "for i in range(SEQUENCE_LENGTH, len(scaled_data) - FORECAST_HORIZON):\n",
    "    X.append(scaled_data[i - SEQUENCE_LENGTH:i])\n",
    "    y.append(df['Label'].iloc[i:i + FORECAST_HORIZON].values)\n",
    "\n",
    "X, y = np.array(X), np.array(y)\n",
    "print(f\"X shape: {X.shape}, y shape: {y.shape}\")  # Debug info"
   ],
   "id": "7aaf04c111873e14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 4- Split dataset\n",
    "\n",
    "# Reserve only the last sample for testing\n",
    "X_train = X[:-1]\n",
    "y_train = y[:-1]  # Shape: (samples, 10)\n",
    "\n",
    "X_test = X[-1:]   # Shape: (1, 60, 5)\n",
    "y_test = y[-1:]   # Shape: (1, 10), still in integer form for now\n",
    "\n",
    "print(f\"Train X: {X_train.shape}, y: {y_train.shape}\")\n",
    "print(f\"Test X: {X_test.shape}, y: {y_test.shape}\")"
   ],
   "id": "9b787dab0031e409",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 5- One-hot encode each timestep's class (3 classes â†’ depth = 3)\n",
    "\n",
    "# One-hot encode training labels\n",
    "y_train_onehot = np.array([to_categorical(row, num_classes=3) for row in y_train])\n",
    "\n",
    "# One-hot encode test labels (for model.evaluate or model.predict accuracy)\n",
    "y_test_onehot = np.array([to_categorical(row, num_classes=3) for row in y_test])\n",
    "\n",
    "# Debug shapes\n",
    "print(f\"y_train_onehot shape: {y_train_onehot.shape}\")  # (samples, 10, 3)\n",
    "print(f\"y_test_onehot shape: {y_test_onehot.shape}\")    # (1, 10, 3)\n"
   ],
   "id": "ba0012e61d11b0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 6- Build LSTM Classification Model\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(SEQUENCE_LENGTH, X.shape[2])),  # (60, 5)\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(FORECAST_HORIZON * 3, activation='softmax'),\n",
    "    Reshape((FORECAST_HORIZON, 3))  # Final output: (10, 3)\n",
    "])\n"
   ],
   "id": "cf91bf473436a97e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 7- Compile model\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=[\n",
    "        tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy'),\n",
    "        tf.keras.metrics.TopKCategoricalAccuracy(k=2, name='top_2_accuracy')\n",
    "    ]\n",
    ")\n",
    "\n"
   ],
   "id": "7b500e9a255ca6e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 8- Fit model\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train_onehot,\n",
    "    epochs=50,                   # adjust based on convergence\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    shuffle=False,               # Important: keep time order!\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n"
   ],
   "id": "f189dd95c6660684",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "67892e8ce905fa80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 9- Load the last 60 candles from a CSV file\n",
    "\n",
    "# Load and clean\n",
    "input_df = pd.read_csv('datasets-18/new-data-for-test/rows-60-from-20240503/rows-60-from-20240503.csv', sep='\\t')\n",
    "input_df.dropna(inplace=True)\n",
    "\n",
    "input_df.rename(columns={\n",
    "    '<DATE>': 'DATE',\n",
    "    '<TIME>': 'TIME',\n",
    "    '<OPEN>': 'OPEN',\n",
    "    '<HIGH>': 'HIGH',\n",
    "    '<LOW>': 'LOW',\n",
    "    '<CLOSE>': 'CLOSE',\n",
    "    '<TICKVOL>': 'TICKVOL',\n",
    "    '<VOL>': 'VOL',\n",
    "    '<SPREAD>': 'SPREAD'\n",
    "}, inplace=True)\n",
    "\n",
    "# Add datetime\n",
    "input_df['DATETIME'] = pd.to_datetime(input_df['DATE'] + ' ' + input_df['TIME'])\n",
    "\n",
    "# Scale\n",
    "input_features = input_df[['OPEN', 'HIGH', 'LOW', 'CLOSE', 'TICKVOL']]\n",
    "input_scaled = scaler.transform(input_features)\n",
    "input_sequence = np.expand_dims(input_scaled, axis=0)  # (1, 60, 5)\n",
    "\n",
    "# Predict\n",
    "pred_probs = model.predict(input_sequence)  # shape: (1, 10, 3)\n",
    "pred_classes = np.argmax(pred_probs[0], axis=1)\n",
    "print(\"Predicted Classes:\", pred_classes)  # 0=no signal, 1=buy, 2=sell\n",
    "\n",
    "# Timestamps for forecast\n",
    "last_timestamp = input_df['DATETIME'].iloc[-1]\n",
    "forecast_datetimes = pd.date_range(start=last_timestamp + pd.Timedelta(hours=1),\n",
    "                                   periods=FORECAST_HORIZON, freq='h')\n",
    "\n",
    "# Output DataFrame\n",
    "predicted_df = pd.DataFrame({\n",
    "    'DATETIME': forecast_datetimes,\n",
    "    'forecast_class': pred_classes\n",
    "})\n",
    "predicted_df['label'] = predicted_df['forecast_class'].map({1: 'buy', 2: 'sell'}).fillna('')\n",
    "\n",
    "print(predicted_df)\n"
   ],
   "id": "b27582fcf9337d79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# plot section",
   "id": "e31209f9cef74d45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 10- Plot section\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, '../utils')\n",
    "import forex_plot_utils\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 10-1 PARAMETERS\n",
    "csv1_path = 'datasets-18/new-data-for-test/rows-60-from-20240503/latest-4-for-history.csv'\n",
    "csv3_path = 'datasets-18/new-data-for-test/rows-60-from-20240503/after.csv'\n",
    "plot_title = 'Write a suitable title.'\n",
    "output_plot_path = None  # e.g., 'output.png'\n",
    "\n",
    "# 10-2 LOAD DATA FROM CSVS\n",
    "historical_df = forex_plot_utils.load_csv_with_datetime(csv1_path) if os.path.exists(csv1_path) else None\n",
    "actual_future_df = forex_plot_utils.load_csv_with_datetime(csv3_path) if os.path.exists(csv3_path) else None\n",
    "# 10-3 Generate forecast timestamps ===\n",
    "# Start 1 hour after the last actual candle\n",
    "last_timestamp = input_df['DATETIME'].iloc[-1]\n",
    "forecast_datetimes = pd.date_range(start=last_timestamp + pd.Timedelta(hours=1), periods=FORECAST_HORIZON , freq='h')\n",
    "\n",
    "# 10-4 Create predicted_df with forecasted trend reversals\n",
    "predicted_df = pd.DataFrame({\n",
    "    'DATETIME': forecast_datetimes,\n",
    "    'forecast_class': pred_classes\n",
    "})\n",
    "\n",
    "# 10-5 Optional: Add labels for plotting\n",
    "def class_to_label(c):\n",
    "    if c == 1:\n",
    "        return 'buy'\n",
    "    elif c == 2:\n",
    "        return 'sell'\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "predicted_df['label'] = predicted_df['forecast_class'].apply(class_to_label)\n"
   ],
   "id": "cf739a571793a98b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 10-6 PLOT\n",
    "\n",
    "forex_plot_utils.plot_all_series(\n",
    "    historical_df=historical_df,\n",
    "    predicted_df=predicted_df,\n",
    "    actual_future_df=actual_future_df,\n",
    "    title=plot_title,\n",
    "    output_path=output_plot_path\n",
    ")"
   ],
   "id": "49ac94a3b618c89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 11- Save Model\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 11-1 Create timestamp and paths\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "model_filename = f'model_{timestamp}.keras'\n",
    "model_path = os.path.join('saved_models', model_filename)\n",
    "\n",
    "# 11-2 Directory to hold logs and extras\n",
    "log_dir = os.path.join('saved_models', f'model_{timestamp}_logs')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# 11-3 Save model\n",
    "model.save(model_path)\n",
    "\n",
    "# 11-4 Save training history\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_csv(os.path.join(log_dir, 'training_history.csv'), index=False)\n",
    "\n",
    "# 11-5 Save training loss plot\n",
    "plt.figure()\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(log_dir, 'training_loss.png'))\n",
    "plt.close()\n",
    "\n",
    "# 11-6 Save model summary and final performance\n",
    "y_test_onehot = to_categorical(y_test, num_classes=3)\n",
    "\n",
    "with open(os.path.join(log_dir, 'model_log.txt'), 'w') as f:\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))\n",
    "    final_train_loss = history.history['loss'][-1]\n",
    "    final_test_loss, final_test_accuracy, final_test_mae = model.evaluate(X_test, y_test_onehot, verbose=0)\n",
    "\n",
    "    f.write(f'\\nFinal Training Loss: {final_train_loss:.6f}\\n')\n",
    "    f.write(f'Final Test Loss: {final_test_loss:.6f}\\n')\n",
    "    f.write(f'Final Test Accuracy: {final_test_accuracy:.6f}\\n')"
   ],
   "id": "c60adc7617c16b75",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
